<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Research Agent - Crash-Resilient Deep Research</title>
  <meta name="description" content="Replace hours of manual research with a single command. Crash-resilient, no character limits, fully automated deep research tool." />
  <link rel="preconnect" href="https://fonts.googleapis.com" />
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=JetBrains+Mono:wght@400;500;700&display=swap" rel="stylesheet" />
  <link rel="stylesheet" href="/src/style.css" />
</head>
<body>

  <!-- ========== Header ========== -->
  <header class="site-header">
    <div class="container">
      <a href="#" class="site-logo"><span>&gt;</span> research-agent</a>
      <nav>
        <a href="#features">Features</a>
        <a href="#pipeline">How It Works</a>
        <a href="#docs">Docs</a>
        <a href="#quickstart">Quick Start</a>
        <a href="#about">About</a>
        <a href="https://github.com/dmhernandez2525/research-agent">GitHub</a>
      </nav>
    </div>
  </header>

  <!-- ========== Hero ========== -->
  <section class="hero" id="hero">
    <div class="container">
      <div class="hero-content">
        <span class="hero-badge">pip install research-agent</span>
        <h1><span class="accent">Research Agent</span></h1>
        <p class="subtitle">Crash-resilient deep research, locally run.</p>
        <p class="description">
          Replace hours of manual Claude.ai research with a single command.
          Crash-resilient, no character limits, fully automated.
        </p>
        <div class="hero-actions">
          <a href="#quickstart" class="btn btn-primary">Get Started</a>
          <a href="https://github.com/dmhernandez2525/research-agent" class="btn btn-secondary">View on GitHub</a>
        </div>
      </div>
    </div>
  </section>

  <!-- ========== Features ========== -->
  <section class="features" id="features">
    <div class="container">
      <div class="section-heading">
        <h2>Why Research Agent?</h2>
        <p>Built for reliability and depth. Every step is saved to disk so nothing is ever lost.</p>
      </div>
      <div class="features-grid">
        <div class="feature-card">
          <div class="feature-icon">
            <svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="color: var(--color-accent);">
              <polyline points="20 6 9 17 4 12"></polyline>
            </svg>
          </div>
          <h3>Crash Resilient</h3>
          <p>Checkpoints after every step. Resume exactly where you left off after any failure &mdash; network errors, rate limits, or unexpected crashes.</p>
        </div>
        <div class="feature-card">
          <div class="feature-icon">
            <svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="color: var(--color-accent);">
              <path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path>
              <polyline points="14 2 14 8 20 8"></polyline>
            </svg>
          </div>
          <h3>No Character Limits</h3>
          <p>Reports can be any length. Each sub-task saves to disk independently, so you are never bound by context windows or output caps.</p>
        </div>
        <div class="feature-card">
          <div class="feature-icon">
            <svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" style="color: var(--color-accent);">
              <polygon points="13 2 3 14 12 14 11 22 21 10 12 10 13 2"></polygon>
            </svg>
          </div>
          <h3>Automated Pipeline</h3>
          <p>One command triggers the full research pipeline. Output feeds directly into your build process &mdash; no copy-pasting required.</p>
        </div>
      </div>
    </div>
  </section>

  <!-- ========== Pipeline ========== -->
  <section class="pipeline" id="pipeline">
    <div class="container">
      <div class="section-heading">
        <h2>How It Works</h2>
        <p>A five-stage pipeline that fans out for parallel research and fans back in for synthesis.</p>
      </div>
      <div class="steps">
        <div class="step">
          <div class="step-number">1</div>
          <div class="step-content">
            <h3>Plan</h3>
            <p>Decomposes your query into 3&ndash;7 independent sub-questions, each targeting a distinct angle of your research topic.</p>
          </div>
        </div>
        <div class="step">
          <div class="step-number">2</div>
          <div class="step-content">
            <h3>Search</h3>
            <p>Tavily semantic search generates 3 query variations per sub-question, maximizing coverage across sources.</p>
          </div>
        </div>
        <div class="step">
          <div class="step-number">3</div>
          <div class="step-content">
            <h3>Scrape</h3>
            <p>Trafilatura content extraction pulls clean text from each URL, with quality scoring to filter noise.</p>
          </div>
        </div>
        <div class="step">
          <div class="step-number">4</div>
          <div class="step-content">
            <h3>Analyze</h3>
            <p>Per-subtask summarization with context management distills findings into structured, sourced notes.</p>
          </div>
        </div>
        <div class="step">
          <div class="step-number">5</div>
          <div class="step-content">
            <h3>Synthesize</h3>
            <p>Final report generation reads all findings from disk and produces a comprehensive, citation-backed document.</p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- ========== Quick Start ========== -->
  <section class="quickstart" id="quickstart">
    <div class="container">
      <div class="section-heading">
        <h2>Quick Start</h2>
        <p>Up and running in under a minute.</p>
      </div>
      <div class="quickstart-block">
        <div class="code-block">
<pre><span class="comment"># Install</span>
<span class="command">pip install</span> research-agent

<span class="comment"># Configure</span>
<span class="command">export</span> ANTHROPIC_API_KEY=<span class="string">your-key</span>
<span class="command">export</span> TAVILY_API_KEY=<span class="string">your-key</span>

<span class="comment"># Research</span>
<span class="command">research-agent</span> <span class="string">"Best practices for building SaaS in 2026"</span></pre>
        </div>
      </div>
    </div>
  </section>

  <!-- ========== Architecture ========== -->
  <section class="architecture" id="architecture">
    <div class="container">
      <div class="section-heading">
        <h2>Architecture</h2>
        <p>Designed for resilience at every layer.</p>
      </div>
      <div class="architecture-content">
        <p>
          Research Agent uses a <strong>fan-out / fan-in</strong> pattern built on LangGraph.
          Your query fans out into independent sub-tasks that run in parallel, each with its own
          checkpoint saved to disk. Results fan back in for final synthesis. A three-tier model
          routing system assigns the right model size to each stage &mdash; fast models for planning
          and searching, capable models for analysis and synthesis.
        </p>
        <p>
          Every step persists its output before moving on. If anything fails, the pipeline
          resumes from the last successful checkpoint. No work is ever repeated.
        </p>
        <div class="architecture-tags">
          <span class="tag">LangGraph</span>
          <span class="tag">Checkpoint-per-step</span>
          <span class="tag">Three-tier model routing</span>
          <span class="tag">Fan-out / Fan-in</span>
          <span class="tag">Disk-first persistence</span>
        </div>
      </div>
    </div>
  </section>

  <!-- ========== Docs ========== -->
  <section class="docs" id="docs">
    <div class="container">
      <div class="section-heading">
        <h2>Documentation</h2>
        <p>Everything you need to configure and run Research Agent.</p>
      </div>
      <div class="docs-grid">
        <div class="docs-card">
          <h3>CLI Options</h3>
          <div class="code-block">
<pre><span class="command">research-agent</span> <span class="string">"query"</span> [OPTIONS]

  <span class="comment">--depth</span>     Number of sub-questions (3-7)
  <span class="comment">--model</span>     LLM model override
  <span class="comment">--budget</span>    Max cost in USD (default: 2.00)
  <span class="comment">--output</span>    Output file path
  <span class="comment">--yes</span>       Auto-approve research plan
  <span class="comment">--config</span>    Path to config.yaml</pre>
          </div>
        </div>
        <div class="docs-card">
          <h3>Configuration</h3>
          <p>Four-layer resolution: defaults, <code>config.yaml</code>, environment variables, CLI arguments. Higher layers override lower ones.</p>
          <div class="code-block">
<pre><span class="comment"># config.yaml</span>
llm:
  provider: <span class="string">"anthropic"</span>
  model: <span class="string">"claude-sonnet-4-5-20250929"</span>
  temperature: <span class="string">0.1</span>

search:
  provider: <span class="string">"tavily"</span>
  max_results: <span class="string">10</span>

costs:
  max_cost_per_run: <span class="string">2.00</span>
  warn_at_percentage: <span class="string">80</span></pre>
          </div>
        </div>
        <div class="docs-card">
          <h3>Environment Variables</h3>
          <div class="code-block">
<pre><span class="comment"># Required</span>
<span class="command">export</span> ANTHROPIC_API_KEY=<span class="string">your-key</span>
<span class="command">export</span> TAVILY_API_KEY=<span class="string">your-key</span>

<span class="comment"># Optional (multi-provider)</span>
<span class="command">export</span> OPENAI_API_KEY=<span class="string">your-key</span>
<span class="command">export</span> GOOGLE_API_KEY=<span class="string">your-key</span>

<span class="comment"># Override nested config via env</span>
LLM__MODEL=<span class="string">gpt-4o-mini</span> research-agent <span class="string">"query"</span></pre>
          </div>
        </div>
        <div class="docs-card">
          <h3>Resume &amp; Recovery</h3>
          <p>Research Agent saves progress after every step. To resume an interrupted session, run the same query again:</p>
          <div class="code-block">
<pre><span class="comment"># First run (interrupted at step 3)</span>
<span class="command">research-agent</span> <span class="string">"SaaS analysis"</span>
<span class="comment"># ^C or crash</span>

<span class="comment"># Resume from last checkpoint</span>
<span class="command">research-agent</span> <span class="string">"SaaS analysis"</span>
<span class="comment"># Output: Resuming from step 'scrape' (3/5)</span></pre>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- ========== About ========== -->
  <section class="about" id="about">
    <div class="container">
      <div class="section-heading">
        <h2>About</h2>
        <p>Part of the "Apps That Build Apps" ecosystem.</p>
      </div>
      <div class="about-content">
        <p>
          Research Agent was built to eliminate the last manual bottleneck in an automated
          software development pipeline. The "Apps That Build Apps" ecosystem uses AI agents
          to generate project prompts, build scaffolding, and develop features &mdash; but the
          research phase still required manually operating Claude.ai in a browser. Copy-pasting
          prompts across sessions, saving outputs, chaining continuations, and losing all
          progress when sessions timed out.
        </p>
        <p>
          Research Agent replaces that entire manual workflow with a single command. It was
          designed from the ground up for <strong>crash resilience</strong> (every step saves
          to disk before moving on), <strong>unlimited output</strong> (synthesis reads files,
          not context), and <strong>cost control</strong> (budget caps with graceful degradation
          to cheaper models).
        </p>
        <p>
          The architecture is informed by a comprehensive survey of 16+ open-source research
          agents including LangChain Open Deep Research, ByteDance DeerFlow, GPT-Researcher,
          and Stanford STORM. Key innovations adopted include the ExpandSearch pattern (34.3%
          improvement over single-query baselines), observation masking (83.9% token savings),
          and atomic checkpoint writes for crash resilience.
        </p>
        <div class="architecture-tags">
          <span class="tag">Python 3.11+</span>
          <span class="tag">LangGraph 1.0</span>
          <span class="tag">Anthropic Claude</span>
          <span class="tag">OpenAI</span>
          <span class="tag">Tavily Search</span>
          <span class="tag">Trafilatura</span>
          <span class="tag">ChromaDB</span>
          <span class="tag">pydantic-settings</span>
          <span class="tag">Typer + Rich</span>
          <span class="tag">structlog</span>
        </div>
      </div>
    </div>
  </section>

  <!-- ========== Footer ========== -->
  <footer class="site-footer">
    <div class="container">
      <p>
        Research Agent is part of the
        <a href="https://github.com/dmhernandez2525">Apps That Build Apps</a>
        ecosystem.
      </p>
    </div>
  </footer>

</body>
</html>
